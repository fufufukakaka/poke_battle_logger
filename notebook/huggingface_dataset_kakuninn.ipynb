{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fdf6d4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T13:19:29.255590Z",
     "start_time": "2023-04-13T13:19:29.069228Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (osxkeychain).\n",
      "Your token has been saved to /Users/yusuke-fukasawa/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8024f4bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T13:19:42.325699Z",
     "start_time": "2023-04-13T13:19:40.900039Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2ef39c48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:17:57.550637Z",
     "start_time": "2023-04-14T04:17:56.437758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6099f08a23aa407998c2d3bad088875d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /Users/yusuke-fukasawa/.cache/huggingface/datasets/imagefolder/default-0eaae17e5fee2248/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985a85c8dd354c91834985f2988137e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3282496e53894b6aa4e66641a7b25a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9815cdb6306412baa388f356e36a3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /Users/yusuke-fukasawa/.cache/huggingface/datasets/imagefolder/default-0eaae17e5fee2248/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"imagefolder\", data_dir=\"../experimental/imgs/\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0c38a7fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:17:58.859884Z",
     "start_time": "2023-04-14T04:17:58.844320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 291\n",
       "})"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "00a21e40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:18:01.366469Z",
     "start_time": "2023-04-14T04:18:01.351274Z"
    }
   },
   "outputs": [],
   "source": [
    "split_dataset = dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2660c0da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T02:38:59.232750Z",
     "start_time": "2023-04-14T02:38:59.221215Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import SwinForImageClassification, SwinConfig, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6939f801",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T02:39:00.711936Z",
     "start_time": "2023-04-14T02:38:59.846004Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "94cdd580",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T02:39:00.728433Z",
     "start_time": "2023-04-14T02:39:00.725401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=70x65>,\n",
       " 'label': 26}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = split_dataset[\"train\"][10]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "21fd1b0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T02:39:02.216438Z",
     "start_time": "2023-04-14T02:39:01.910832Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yusuke-fukasawa/Library/Caches/pypoetry/virtualenvs/poke-battle-logger-xYV7PrtE-py3.10/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViTFeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n",
       "  \"image_mean\": [\n",
       "    0.485,\n",
       "    0.456,\n",
       "    0.406\n",
       "  ],\n",
       "  \"image_processor_type\": \"ViTFeatureExtractor\",\n",
       "  \"image_std\": [\n",
       "    0.229,\n",
       "    0.224,\n",
       "    0.225\n",
       "  ],\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"height\": 224,\n",
       "    \"width\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/swin-base-patch4-window7-224-in22k\")\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5501c965",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T02:39:03.102128Z",
     "start_time": "2023-04-14T02:39:03.095877Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "train_transforms = Compose(\n",
    "        [\n",
    "            RandomResizedCrop((feature_extractor.size[\"width\"], feature_extractor.size[\"height\"])),\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "val_transforms = Compose(\n",
    "        [\n",
    "            Resize((feature_extractor.size[\"width\"], feature_extractor.size[\"height\"])),\n",
    "            CenterCrop((feature_extractor.size[\"width\"], feature_extractor.size[\"height\"])),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def preprocess_train(example_batch):\n",
    "    \"\"\"Apply train_transforms across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [\n",
    "        train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    return example_batch\n",
    "\n",
    "def preprocess_val(example_batch):\n",
    "    \"\"\"Apply val_transforms across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
    "    return example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6e854362",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:18:11.736545Z",
     "start_time": "2023-04-14T04:18:11.724124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'アラブルタケ'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = split_dataset[\"train\"].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label\n",
    "\n",
    "id2label[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "55c17531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:18:13.267775Z",
     "start_time": "2023-04-14T04:18:13.244458Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = split_dataset['train']\n",
    "val_ds = split_dataset['test']\n",
    "\n",
    "train_ds.set_transform(preprocess_train)\n",
    "val_ds.set_transform(preprocess_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f2f45568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T05:01:15.899142Z",
     "start_time": "2023-04-14T05:01:15.090824Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-base-patch4-window7-224-in22k and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([21841, 1024]) in the checkpoint and torch.Size([100, 1024]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([21841]) in the checkpoint and torch.Size([100]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\"microsoft/swin-base-patch4-window7-224-in22k\",\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    ignore_mismatched_sizes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f10929fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:18:17.690735Z",
     "start_time": "2023-04-14T04:18:17.673148Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"pokemon_image_classifier\"\n",
    "batch_size = 16\n",
    "\n",
    "args = TrainingArguments(\n",
    "    model_name,\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=20,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "017ad54d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:18:19.142796Z",
     "start_time": "2023-04-14T04:18:19.126376Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# the compute_metrics function takes a Named Tuple as input:\n",
    "# predictions, which are the logits of the model as Numpy arrays,\n",
    "# and label_ids, which are the ground-truth labels as Numpy arrays.\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3befac84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:18:19.759828Z",
     "start_time": "2023-04-14T04:18:19.742797Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ce336fa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:18:20.501024Z",
     "start_time": "2023-04-14T04:18:20.450303Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8fdbc9bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:37:18.488920Z",
     "start_time": "2023-04-14T04:18:21.651044Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yusuke-fukasawa/Library/Caches/pypoetry/virtualenvs/poke-battle-logger-xYV7PrtE-py3.10/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 18:42, Epoch 18/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.614583</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.388228</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.484100</td>\n",
       "      <td>3.948808</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.484100</td>\n",
       "      <td>3.355379</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.296700</td>\n",
       "      <td>2.889433</td>\n",
       "      <td>0.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.296700</td>\n",
       "      <td>2.446525</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.296700</td>\n",
       "      <td>2.081670</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.834700</td>\n",
       "      <td>1.641603</td>\n",
       "      <td>0.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.834700</td>\n",
       "      <td>1.342672</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.036700</td>\n",
       "      <td>1.092502</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.036700</td>\n",
       "      <td>0.906724</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.615700</td>\n",
       "      <td>0.712422</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.615700</td>\n",
       "      <td>0.562905</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.615700</td>\n",
       "      <td>0.466648</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.412900</td>\n",
       "      <td>0.383826</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.412900</td>\n",
       "      <td>0.315346</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.285938</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.336000</td>\n",
       "      <td>0.274546</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.319500</td>\n",
       "      <td>0.271233</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       18.82\n",
      "  total_flos               = 359549526GF\n",
      "  train_loss               =       1.542\n",
      "  train_runtime            =  0:18:56.47\n",
      "  train_samples_per_second =       4.593\n",
      "  train_steps_per_second   =        0.07\n"
     ]
    }
   ],
   "source": [
    "train_results = trainer.train()\n",
    "# rest is optional but nice to have\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "88908552",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:38:12.824895Z",
     "start_time": "2023-04-14T04:38:10.162032Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =      18.82\n",
      "  eval_accuracy           =     0.9667\n",
      "  eval_loss               =     0.3153\n",
      "  eval_runtime            = 0:00:02.65\n",
      "  eval_samples_per_second =      11.29\n",
      "  eval_steps_per_second   =      0.753\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "# some nice to haves:\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b519d128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:14:47.580130Z",
     "start_time": "2023-04-14T04:14:47.370869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.5144233107566833, 'label': 'へイラッシャ'},\n",
       " {'score': 0.41433167457580566, 'label': 'ヘイラッシャ'},\n",
       " {'score': 0.006614611018449068, 'label': 'セグレイブ'},\n",
       " {'score': 0.0057674297131598, 'label': 'ドンファン'},\n",
       " {'score': 0.002799961483106017, 'label': 'ドオー'}]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 推論テスト\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier_pipe = pipeline(task=\"image-classification\", model=trainer.model, feature_extractor=feature_extractor)\n",
    "pokemon_image = cv2.imread(\"../template_images/labeled_pokemon_templates/へイラッシャ_1920.png\")\n",
    "pokemon_image2 = cv2.cvtColor(pokemon_image, cv2.COLOR_BGR2RGB)\n",
    "pokemon_image3 = Image.fromarray(pokemon_image2)\n",
    "classifier_pipe(pokemon_image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "19b00adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T23:46:37.332742Z",
     "start_time": "2023-04-13T23:46:37.309377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=70x65>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds[0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4a9472e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-13T23:46:38.440881Z",
     "start_time": "2023-04-13T23:46:38.194738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9922673106193542, 'label': 'ハバタクカミ'},\n",
       " {'score': 0.0012425959575921297, 'label': 'ディンルー'},\n",
       " {'score': 0.000875094614457339, 'label': 'バンバドロ'},\n",
       " {'score': 0.00028816444682888687, 'label': 'サザンドラ'},\n",
       " {'score': 0.0002775873872451484, 'label': 'パルシェン'}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_pipe(val_ds[0]['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9ba23306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:38:21.984172Z",
     "start_time": "2023-04-14T04:38:16.714124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'score': 0.9651775360107422, 'label': 'ヤミラミ'} ヤミラミ\n",
      "1 {'score': 0.971068263053894, 'label': 'ミミッキュ'} ミミッキュ\n",
      "2 {'score': 0.9843270182609558, 'label': 'ドドゲザン'} ドドゲザン\n",
      "3 {'score': 0.9755663275718689, 'label': 'キノガッサ'} キノガッサ\n",
      "4 {'score': 0.9437559843063354, 'label': 'グレンアルマ'} グレンアルマ\n",
      "5 {'score': 0.9386981129646301, 'label': 'ソウブレイズ'} ソウブレイズ\n",
      "6 {'score': 0.9957389831542969, 'label': 'ハバタクカミ'} ハバタクカミ\n",
      "7 {'score': 0.5144233107566833, 'label': 'へイラッシャ'} へイラッシャ\n",
      "8 {'score': 0.8641415238380432, 'label': 'カバルドン'} カバルドン\n",
      "9 {'score': 0.6382536292076111, 'label': 'ウインディ'} ウインディ\n",
      "10 {'score': 0.367607057094574, 'label': 'ハルクジラ'} ハルクジラ\n",
      "11 {'score': 0.9870359301567078, 'label': 'トドロクツキ'} トドロクツキ\n",
      "12 {'score': 0.9752021431922913, 'label': 'メタモン'} メタモン\n",
      "13 {'score': 0.9939765930175781, 'label': 'ヌメルゴン'} ヌメルゴン\n",
      "14 {'score': 0.9909362196922302, 'label': 'サーフゴー'} サーフゴー\n",
      "15 {'score': 0.7864248752593994, 'label': 'ウルガモス'} ウルガモス\n",
      "16 {'score': 0.9438540935516357, 'label': 'テツノツツミ'} テツノツツミ\n",
      "17 {'score': 0.9987615346908569, 'label': 'ディンルー'} ディンルー\n",
      "18 {'score': 0.6477733850479126, 'label': 'ルガルガンたそがれ'} ルガルガンたそがれ\n",
      "19 {'score': 0.9558506011962891, 'label': 'ガブリアス'} ガブリアス\n",
      "20 {'score': 0.9865363240242004, 'label': 'ドンファン'} ドンファン\n",
      "21 {'score': 0.9751937389373779, 'label': 'バンギラス'} バンギラス\n",
      "22 {'score': 0.9727897047996521, 'label': 'ラウドボーン'} ラウドボーン\n",
      "23 {'score': 0.6119913458824158, 'label': 'アマージョ'} アマージョ\n",
      "24 {'score': 0.9768253564834595, 'label': 'バンギラス'} バンギラス\n",
      "25 {'score': 0.42944544553756714, 'label': 'イルカマン'} イルカマン\n",
      "26 {'score': 0.9914421439170837, 'label': 'サザンドラ'} サザンドラ\n",
      "27 {'score': 0.8693450689315796, 'label': 'カバルドン'} カバルドン\n",
      "28 {'score': 0.9985796213150024, 'label': 'キョジオーン'} キョジオーン\n",
      "29 {'score': 0.9914625287055969, 'label': 'ヌメルゴン'} ヌメルゴン\n"
     ]
    }
   ],
   "source": [
    "for idx, _val in enumerate(val_ds):\n",
    "    predict = classifier_pipe(_val['image'])\n",
    "    _label = id2label[_val[\"label\"]]\n",
    "    print(idx, predict[0], _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "87edd2bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:42:11.677116Z",
     "start_time": "2023-04-14T04:42:10.917145Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/fufufukakaka/pokemon_image_classifier/blob/refs%2Fpr%2F7/config.json'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import upload_file\n",
    "\n",
    "upload_file(\n",
    "    path_or_fileobj=\"pokemon_image_classifier/config.json\",\n",
    "    path_in_repo=\"config.json\",\n",
    "    repo_id=\"fufufukakaka/pokemon_image_classifier\",\n",
    "    create_pr=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "97d36de9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:47:38.626340Z",
     "start_time": "2023-04-14T04:42:17.337555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25f20a21ef55412281bc10eba4ad9fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a92ddba8b564b61a3e902c29c534986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/348M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/fufufukakaka/pokemon_image_classifier/blob/refs%2Fpr%2F9/pytorch_model.bin'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_file(\n",
    "    path_or_fileobj=\"pokemon_image_classifier/pytorch_model.bin\",\n",
    "    path_in_repo=\"pytorch_model.bin\",\n",
    "    repo_id=\"fufufukakaka/pokemon_image_classifier\",\n",
    "    create_pr=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "182adc1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T04:42:15.618098Z",
     "start_time": "2023-04-14T04:42:14.901114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/fufufukakaka/pokemon_image_classifier/blob/refs%2Fpr%2F8/preprocessor_config.json'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_file(\n",
    "    path_or_fileobj=\"pokemon_image_classifier/preprocessor_config.json\",\n",
    "    path_in_repo=\"preprocessor_config.json\",\n",
    "    repo_id=\"fufufukakaka/pokemon_image_classifier\",\n",
    "    create_pr=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
