{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fdf6d4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:21:24.520368Z",
     "start_time": "2023-04-26T13:21:24.335706Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8024f4bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:21:38.689439Z",
     "start_time": "2023-04-26T13:21:37.778727Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef39c48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:21:41.056310Z",
     "start_time": "2023-04-26T13:21:39.759929Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174cc2eb666245aeb700df2838698c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imagefolder/default to /Users/yusuke-fukasawa/.cache/huggingface/datasets/imagefolder/default-7270ff668b601736/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c81a9660a68455c94ae0605cfd9dfdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/307 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27e320fc5dc4d0eaa1c738b44a670e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f439230921f4305b35bb3f006698952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imagefolder downloaded and prepared to /Users/yusuke-fukasawa/.cache/huggingface/datasets/imagefolder/default-7270ff668b601736/0.0.0/37fbb85cc714a338bea574ac6c7d0b5be5aff46c1862c1989b20e0771199e93f. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"imagefolder\", data_dir=\"../experimental/imgs/\", split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c38a7fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:21:43.055215Z",
     "start_time": "2023-04-26T13:21:43.040795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['image', 'label'],\n",
       "    num_rows: 307\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00a21e40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:21:45.792105Z",
     "start_time": "2023-04-26T13:21:45.779539Z"
    }
   },
   "outputs": [],
   "source": [
    "split_dataset = dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2660c0da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:21:47.784515Z",
     "start_time": "2023-04-26T13:21:46.725823Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import SwinForImageClassification, SwinConfig, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6939f801",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:22:41.165361Z",
     "start_time": "2023-04-26T13:22:29.674308Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94cdd580",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:22:42.882657Z",
     "start_time": "2023-04-26T13:22:42.865378Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=105x100>,\n",
       " 'label': 28}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = split_dataset[\"train\"][10]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21fd1b0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:22:44.543800Z",
     "start_time": "2023-04-26T13:22:44.279058Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yusuke-fukasawa/Library/Caches/pypoetry/virtualenvs/poke-battle-logger-xYV7PrtE-py3.10/lib/python3.10/site-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViTFeatureExtractor {\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"feature_extractor_type\": \"ViTFeatureExtractor\",\n",
       "  \"image_mean\": [\n",
       "    0.485,\n",
       "    0.456,\n",
       "    0.406\n",
       "  ],\n",
       "  \"image_processor_type\": \"ViTFeatureExtractor\",\n",
       "  \"image_std\": [\n",
       "    0.229,\n",
       "    0.224,\n",
       "    0.225\n",
       "  ],\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"height\": 224,\n",
       "    \"width\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/swin-base-patch4-window7-224-in22k\")\n",
    "feature_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5501c965",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:22:46.936489Z",
     "start_time": "2023-04-26T13:22:46.623765Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")\n",
    "\n",
    "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "train_transforms = Compose(\n",
    "        [\n",
    "            RandomResizedCrop((feature_extractor.size[\"width\"], feature_extractor.size[\"height\"])),\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "val_transforms = Compose(\n",
    "        [\n",
    "            Resize((feature_extractor.size[\"width\"], feature_extractor.size[\"height\"])),\n",
    "            CenterCrop((feature_extractor.size[\"width\"], feature_extractor.size[\"height\"])),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def preprocess_train(example_batch):\n",
    "    \"\"\"Apply train_transforms across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [\n",
    "        train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    return example_batch\n",
    "\n",
    "def preprocess_val(example_batch):\n",
    "    \"\"\"Apply val_transforms across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [val_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]]\n",
    "    return example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e854362",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:22:48.162349Z",
     "start_time": "2023-04-26T13:22:48.158197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'アーマーガア'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = split_dataset[\"train\"].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = i\n",
    "    id2label[i] = label\n",
    "\n",
    "id2label[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55c17531",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:22:49.470782Z",
     "start_time": "2023-04-26T13:22:49.463362Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = split_dataset['train']\n",
    "val_ds = split_dataset['test']\n",
    "\n",
    "train_ds.set_transform(preprocess_train)\n",
    "val_ds.set_transform(preprocess_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2f45568",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:22:51.583928Z",
     "start_time": "2023-04-26T13:22:50.718414Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-base-patch4-window7-224-in22k and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([21841, 1024]) in the checkpoint and torch.Size([105, 1024]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([21841]) in the checkpoint and torch.Size([105]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\"microsoft/swin-base-patch4-window7-224-in22k\",\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    "    ignore_mismatched_sizes = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f10929fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:22:54.516444Z",
     "start_time": "2023-04-26T13:22:54.511568Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"pokemon_image_classifier\"\n",
    "batch_size = 16\n",
    "\n",
    "args = TrainingArguments(\n",
    "    model_name,\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=20,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "017ad54d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:22:56.321274Z",
     "start_time": "2023-04-26T13:22:56.318809Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# the compute_metrics function takes a Named Tuple as input:\n",
    "# predictions, which are the logits of the model as Numpy arrays,\n",
    "# and label_ids, which are the ground-truth labels as Numpy arrays.\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3befac84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:22:57.161283Z",
     "start_time": "2023-04-26T13:22:57.158217Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce336fa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:22:58.249278Z",
     "start_time": "2023-04-26T13:22:58.237464Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fdbc9bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T13:45:05.479543Z",
     "start_time": "2023-04-26T13:22:59.330889Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yusuke-fukasawa/Library/Caches/pypoetry/virtualenvs/poke-battle-logger-xYV7PrtE-py3.10/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 21:47, Epoch 17/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.740745</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.494389</td>\n",
       "      <td>0.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.565000</td>\n",
       "      <td>4.248820</td>\n",
       "      <td>0.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.565000</td>\n",
       "      <td>3.800315</td>\n",
       "      <td>0.193548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.583200</td>\n",
       "      <td>3.338675</td>\n",
       "      <td>0.225806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.583200</td>\n",
       "      <td>2.782559</td>\n",
       "      <td>0.451613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.164600</td>\n",
       "      <td>2.348866</td>\n",
       "      <td>0.516129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.164600</td>\n",
       "      <td>1.847039</td>\n",
       "      <td>0.677419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.117200</td>\n",
       "      <td>1.473042</td>\n",
       "      <td>0.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.117200</td>\n",
       "      <td>1.077031</td>\n",
       "      <td>0.935484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.117200</td>\n",
       "      <td>0.857642</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.727000</td>\n",
       "      <td>0.671330</td>\n",
       "      <td>0.967742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.727000</td>\n",
       "      <td>0.539734</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.494400</td>\n",
       "      <td>0.426809</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.494400</td>\n",
       "      <td>0.375745</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.463200</td>\n",
       "      <td>0.331801</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.463200</td>\n",
       "      <td>0.314374</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.376600</td>\n",
       "      <td>0.309161</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** train metrics *****\n",
      "  epoch                    =       17.78\n",
      "  total_flos               = 359132421GF\n",
      "  train_loss               =      1.6864\n",
      "  train_runtime            =  0:22:05.73\n",
      "  train_samples_per_second =       4.164\n",
      "  train_steps_per_second   =        0.06\n"
     ]
    }
   ],
   "source": [
    "train_results = trainer.train()\n",
    "# rest is optional but nice to have\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88908552",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T20:14:56.316897Z",
     "start_time": "2023-04-26T20:14:52.913935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** eval metrics *****\n",
      "  epoch                   =      17.78\n",
      "  eval_accuracy           =        1.0\n",
      "  eval_loss               =     0.5397\n",
      "  eval_runtime            = 0:00:03.39\n",
      "  eval_samples_per_second =      9.121\n",
      "  eval_steps_per_second   =      0.588\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.evaluate()\n",
    "# some nice to haves:\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b519d128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T20:15:02.832595Z",
     "start_time": "2023-04-26T20:15:02.515958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.9263414144515991, 'label': 'アラブルタケ'},\n",
       " {'score': 0.002636504825204611, 'label': 'フォレトス'},\n",
       " {'score': 0.0023514884524047375, 'label': 'リングマ'},\n",
       " {'score': 0.0022255070507526398, 'label': 'ヤドラン'},\n",
       " {'score': 0.0021616534795612097, 'label': 'イーユイ'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 推論テスト\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier_pipe = pipeline(task=\"image-classification\", model=trainer.model, feature_extractor=feature_extractor)\n",
    "pokemon_image = cv2.imread(\"../template_images/labeled_pokemon_templates/アラブルタケ_1920.png\")\n",
    "pokemon_image2 = cv2.cvtColor(pokemon_image, cv2.COLOR_BGR2RGB)\n",
    "pokemon_image3 = Image.fromarray(pokemon_image2)\n",
    "classifier_pipe(pokemon_image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19b00adc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T20:15:05.023160Z",
     "start_time": "2023-04-26T20:15:05.018080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=70x65>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds[0]['image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a9472e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T20:15:06.221109Z",
     "start_time": "2023-04-26T20:15:06.048740Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.739477276802063, 'label': 'クエスパトラ'},\n",
       " {'score': 0.03022746369242668, 'label': 'ハルクジラ'},\n",
       " {'score': 0.02420826256275177, 'label': 'ノココッチ'},\n",
       " {'score': 0.014066067524254322, 'label': 'ハカドッグ'},\n",
       " {'score': 0.012225240468978882, 'label': 'ミミズズ'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_pipe(val_ds[0]['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ba23306",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T20:15:15.640855Z",
     "start_time": "2023-04-26T20:15:10.127954Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 {'score': 0.739477276802063, 'label': 'クエスパトラ'} クエスパトラ\n",
      "1 {'score': 0.15559238195419312, 'label': 'トリトドン'} トリトドン\n",
      "2 {'score': 0.23894307017326355, 'label': 'トドロクツキ'} トドロクツキ\n",
      "3 {'score': 0.45865508913993835, 'label': 'シャワーズ'} シャワーズ\n",
      "4 {'score': 0.5059671998023987, 'label': 'ルチャブル'} ルチャブル\n",
      "5 {'score': 0.7001776695251465, 'label': 'チヲハウハネ'} チヲハウハネ\n",
      "6 {'score': 0.9923266768455505, 'label': 'サーフゴー'} サーフゴー\n",
      "7 {'score': 0.7816737294197083, 'label': 'ゴチルゼル'} ゴチルゼル\n",
      "8 {'score': 0.46235355734825134, 'label': 'ライチュウ'} ライチュウ\n",
      "9 {'score': 0.8790514469146729, 'label': 'ルカリオ'} ルカリオ\n",
      "10 {'score': 0.2995338439941406, 'label': 'ハリテヤマ'} ハリテヤマ\n",
      "11 {'score': 0.6861193180084229, 'label': 'デカヌチャン'} デカヌチャン\n",
      "12 {'score': 0.4752463698387146, 'label': 'ギャラドス'} ギャラドス\n",
      "13 {'score': 0.9858078956604004, 'label': 'ミミズズ'} ミミズズ\n",
      "14 {'score': 0.9900426864624023, 'label': 'ヌメルゴン'} ヌメルゴン\n",
      "15 {'score': 0.9941393136978149, 'label': 'ヌメルゴン'} ヌメルゴン\n",
      "16 {'score': 0.35321030020713806, 'label': 'ジバコイル'} ジバコイル\n",
      "17 {'score': 0.20036615431308746, 'label': 'ジバコイル'} ジバコイル\n",
      "18 {'score': 0.5997495055198669, 'label': 'テツノワダチ'} テツノワダチ\n",
      "19 {'score': 0.5955870747566223, 'label': 'アマージョ'} アマージョ\n",
      "20 {'score': 0.7945789098739624, 'label': 'ソウブレイズ'} ソウブレイズ\n",
      "21 {'score': 0.4475357234477997, 'label': 'ジバコイル'} ジバコイル\n",
      "22 {'score': 0.566687285900116, 'label': 'オリーヴァ'} オリーヴァ\n",
      "23 {'score': 0.17474888265132904, 'label': 'オーロンゲ'} オーロンゲ\n",
      "24 {'score': 0.6807416677474976, 'label': 'チオンジェン'} チオンジェン\n",
      "25 {'score': 0.8943018913269043, 'label': 'イーユイ'} イーユイ\n",
      "26 {'score': 0.33113017678260803, 'label': 'ドドゲザン'} ドドゲザン\n",
      "27 {'score': 0.9897423982620239, 'label': 'コノヨザル'} コノヨザル\n",
      "28 {'score': 0.9473530054092407, 'label': 'エルレイド'} エルレイド\n",
      "29 {'score': 0.9930514097213745, 'label': 'ハバタクカミ'} ハバタクカミ\n",
      "30 {'score': 0.5091217160224915, 'label': 'テツノブジン'} テツノブジン\n"
     ]
    }
   ],
   "source": [
    "for idx, _val in enumerate(val_ds):\n",
    "    predict = classifier_pipe(_val['image'])\n",
    "    _label = id2label[_val[\"label\"]]\n",
    "    print(idx, predict[0], _label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87edd2bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T20:15:41.186125Z",
     "start_time": "2023-04-26T20:15:40.390303Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/fufufukakaka/pokemon_image_classifier/blob/refs%2Fpr%2F13/config.json'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import upload_file\n",
    "\n",
    "upload_file(\n",
    "    path_or_fileobj=\"pokemon_image_classifier/config.json\",\n",
    "    path_in_repo=\"config.json\",\n",
    "    repo_id=\"fufufukakaka/pokemon_image_classifier\",\n",
    "    create_pr=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97d36de9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-26T20:20:57.066583Z",
     "start_time": "2023-04-26T20:15:43.942831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261d332995484ef58f53fab7f7783363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fb813159ab040bdaa69da0a60ef3065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/348M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/fufufukakaka/pokemon_image_classifier/blob/refs%2Fpr%2F14/pytorch_model.bin'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_file(\n",
    "    path_or_fileobj=\"pokemon_image_classifier/pytorch_model.bin\",\n",
    "    path_in_repo=\"pytorch_model.bin\",\n",
    "    repo_id=\"fufufukakaka/pokemon_image_classifier\",\n",
    "    create_pr=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "182adc1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-19T12:53:17.922041Z",
     "start_time": "2023-04-19T12:53:16.854183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/fufufukakaka/pokemon_image_classifier/blob/refs%2Fpr%2F12/preprocessor_config.json'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_file(\n",
    "    path_or_fileobj=\"pokemon_image_classifier/preprocessor_config.json\",\n",
    "    path_in_repo=\"preprocessor_config.json\",\n",
    "    repo_id=\"fufufukakaka/pokemon_image_classifier\",\n",
    "    create_pr=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
